{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccf0208-a593-4cc4-ac28-bc370bbb7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ccaef7-ae07-4808-829c-387a2983805d",
   "metadata": {},
   "source": [
    "## Preparing the Data for Cancer Type Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2e934b-e56f-40c8-a62f-2f71b30b2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renal = pd.read_csv('/Users/ledamduyen/Desktop/CS 539/project/dataset/clean/renal.csv')\n",
    "df_normal = pd.read_csv('/Users/ledamduyen/Desktop/CS 539/project/dataset/clean/normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fa2533-62ed-473c-8aff-ef0f7c562bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_df(cancer_df, normal_df, cancer_type):\n",
    "    cancer_count = len(cancer_df)\n",
    "    normal_sample = normal_df.sample(n=cancer_count, random_state=11, replace=False)\n",
    "\n",
    "    combined_df = pd.concat([cancer_df, normal_sample], ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac0563e-8dba-4622-bab2-f27ffa937c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renal_cancer = create_combined_df(df_renal, df_normal, 'renal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d674818-8fbb-4826-a955-0400ed7d8dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.176833</td>\n",
       "      <td>8.096554</td>\n",
       "      <td>7.273344</td>\n",
       "      <td>8.181626</td>\n",
       "      <td>2.499844</td>\n",
       "      <td>7.881215</td>\n",
       "      <td>5.276175</td>\n",
       "      <td>4.867742</td>\n",
       "      <td>10.289692</td>\n",
       "      <td>3.285293</td>\n",
       "      <td>...</td>\n",
       "      <td>11.181759</td>\n",
       "      <td>10.762042</td>\n",
       "      <td>12.961899</td>\n",
       "      <td>12.688069</td>\n",
       "      <td>3.725097</td>\n",
       "      <td>3.438851</td>\n",
       "      <td>2.985189</td>\n",
       "      <td>2.687256</td>\n",
       "      <td>3.182581</td>\n",
       "      <td>3.151897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.398563</td>\n",
       "      <td>7.705136</td>\n",
       "      <td>5.539738</td>\n",
       "      <td>9.639625</td>\n",
       "      <td>2.606360</td>\n",
       "      <td>7.527843</td>\n",
       "      <td>5.515707</td>\n",
       "      <td>5.380585</td>\n",
       "      <td>8.251765</td>\n",
       "      <td>3.226581</td>\n",
       "      <td>...</td>\n",
       "      <td>11.278896</td>\n",
       "      <td>10.922836</td>\n",
       "      <td>13.101919</td>\n",
       "      <td>12.879850</td>\n",
       "      <td>3.575279</td>\n",
       "      <td>3.394276</td>\n",
       "      <td>2.951872</td>\n",
       "      <td>2.595775</td>\n",
       "      <td>3.004451</td>\n",
       "      <td>3.046263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.391154</td>\n",
       "      <td>7.844691</td>\n",
       "      <td>6.859150</td>\n",
       "      <td>9.706051</td>\n",
       "      <td>2.832692</td>\n",
       "      <td>8.091542</td>\n",
       "      <td>5.529405</td>\n",
       "      <td>5.072060</td>\n",
       "      <td>10.077566</td>\n",
       "      <td>3.227613</td>\n",
       "      <td>...</td>\n",
       "      <td>11.186446</td>\n",
       "      <td>10.775110</td>\n",
       "      <td>12.952916</td>\n",
       "      <td>12.706673</td>\n",
       "      <td>3.756748</td>\n",
       "      <td>3.593477</td>\n",
       "      <td>3.179602</td>\n",
       "      <td>2.670777</td>\n",
       "      <td>3.067572</td>\n",
       "      <td>3.205570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.735776</td>\n",
       "      <td>8.011649</td>\n",
       "      <td>5.898992</td>\n",
       "      <td>9.988369</td>\n",
       "      <td>2.947561</td>\n",
       "      <td>7.219124</td>\n",
       "      <td>5.617897</td>\n",
       "      <td>5.050528</td>\n",
       "      <td>6.401838</td>\n",
       "      <td>3.129943</td>\n",
       "      <td>...</td>\n",
       "      <td>11.114506</td>\n",
       "      <td>10.843346</td>\n",
       "      <td>13.076192</td>\n",
       "      <td>12.767658</td>\n",
       "      <td>3.747672</td>\n",
       "      <td>3.292814</td>\n",
       "      <td>2.999690</td>\n",
       "      <td>2.707248</td>\n",
       "      <td>3.185152</td>\n",
       "      <td>3.118335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.435494</td>\n",
       "      <td>8.015729</td>\n",
       "      <td>6.849532</td>\n",
       "      <td>8.852354</td>\n",
       "      <td>2.504070</td>\n",
       "      <td>7.337607</td>\n",
       "      <td>5.017304</td>\n",
       "      <td>5.118793</td>\n",
       "      <td>6.924959</td>\n",
       "      <td>3.555628</td>\n",
       "      <td>...</td>\n",
       "      <td>11.049942</td>\n",
       "      <td>10.619544</td>\n",
       "      <td>12.897566</td>\n",
       "      <td>12.632525</td>\n",
       "      <td>3.824783</td>\n",
       "      <td>3.472515</td>\n",
       "      <td>2.928189</td>\n",
       "      <td>2.604355</td>\n",
       "      <td>3.118041</td>\n",
       "      <td>3.041668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>11.532318</td>\n",
       "      <td>8.295377</td>\n",
       "      <td>8.032560</td>\n",
       "      <td>9.287000</td>\n",
       "      <td>5.237196</td>\n",
       "      <td>8.544502</td>\n",
       "      <td>6.221281</td>\n",
       "      <td>6.446083</td>\n",
       "      <td>7.601814</td>\n",
       "      <td>5.597363</td>\n",
       "      <td>...</td>\n",
       "      <td>13.002976</td>\n",
       "      <td>12.574812</td>\n",
       "      <td>14.100213</td>\n",
       "      <td>13.910309</td>\n",
       "      <td>5.495707</td>\n",
       "      <td>5.550453</td>\n",
       "      <td>4.587382</td>\n",
       "      <td>4.348775</td>\n",
       "      <td>4.871972</td>\n",
       "      <td>4.730194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>10.601131</td>\n",
       "      <td>6.426123</td>\n",
       "      <td>5.493845</td>\n",
       "      <td>7.712389</td>\n",
       "      <td>3.569760</td>\n",
       "      <td>7.993786</td>\n",
       "      <td>5.969634</td>\n",
       "      <td>4.660047</td>\n",
       "      <td>7.245230</td>\n",
       "      <td>3.763940</td>\n",
       "      <td>...</td>\n",
       "      <td>13.509037</td>\n",
       "      <td>13.119966</td>\n",
       "      <td>14.622678</td>\n",
       "      <td>14.482744</td>\n",
       "      <td>8.804711</td>\n",
       "      <td>4.897431</td>\n",
       "      <td>6.028813</td>\n",
       "      <td>2.748260</td>\n",
       "      <td>3.739844</td>\n",
       "      <td>3.184603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>10.456393</td>\n",
       "      <td>6.492040</td>\n",
       "      <td>6.147456</td>\n",
       "      <td>7.867307</td>\n",
       "      <td>3.705554</td>\n",
       "      <td>7.129797</td>\n",
       "      <td>5.843678</td>\n",
       "      <td>5.287788</td>\n",
       "      <td>5.400974</td>\n",
       "      <td>3.867667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.011763</td>\n",
       "      <td>11.424249</td>\n",
       "      <td>13.652698</td>\n",
       "      <td>13.495931</td>\n",
       "      <td>4.033132</td>\n",
       "      <td>3.697196</td>\n",
       "      <td>3.484437</td>\n",
       "      <td>3.505660</td>\n",
       "      <td>3.900688</td>\n",
       "      <td>3.830304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>9.736553</td>\n",
       "      <td>6.085462</td>\n",
       "      <td>5.575046</td>\n",
       "      <td>10.184738</td>\n",
       "      <td>2.502134</td>\n",
       "      <td>7.013732</td>\n",
       "      <td>5.174297</td>\n",
       "      <td>4.270660</td>\n",
       "      <td>6.164104</td>\n",
       "      <td>5.851820</td>\n",
       "      <td>...</td>\n",
       "      <td>12.588995</td>\n",
       "      <td>11.769854</td>\n",
       "      <td>13.926275</td>\n",
       "      <td>13.862556</td>\n",
       "      <td>10.171430</td>\n",
       "      <td>7.839900</td>\n",
       "      <td>9.014192</td>\n",
       "      <td>2.289525</td>\n",
       "      <td>2.987165</td>\n",
       "      <td>2.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>10.386735</td>\n",
       "      <td>7.403433</td>\n",
       "      <td>6.964953</td>\n",
       "      <td>7.563864</td>\n",
       "      <td>2.896664</td>\n",
       "      <td>8.834118</td>\n",
       "      <td>5.087135</td>\n",
       "      <td>7.664488</td>\n",
       "      <td>9.760174</td>\n",
       "      <td>3.999645</td>\n",
       "      <td>...</td>\n",
       "      <td>12.504308</td>\n",
       "      <td>11.773247</td>\n",
       "      <td>13.916767</td>\n",
       "      <td>13.644173</td>\n",
       "      <td>3.629679</td>\n",
       "      <td>3.551091</td>\n",
       "      <td>3.064020</td>\n",
       "      <td>2.982234</td>\n",
       "      <td>3.360652</td>\n",
       "      <td>3.114210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1007_s_at   1053_at    117_at     121_at  1255_g_at   1294_at   1316_at  \\\n",
       "0     9.176833  8.096554  7.273344   8.181626   2.499844  7.881215  5.276175   \n",
       "1    10.398563  7.705136  5.539738   9.639625   2.606360  7.527843  5.515707   \n",
       "2    10.391154  7.844691  6.859150   9.706051   2.832692  8.091542  5.529405   \n",
       "3    10.735776  8.011649  5.898992   9.988369   2.947561  7.219124  5.617897   \n",
       "4     9.435494  8.015729  6.849532   8.852354   2.504070  7.337607  5.017304   \n",
       "..         ...       ...       ...        ...        ...       ...       ...   \n",
       "153  11.532318  8.295377  8.032560   9.287000   5.237196  8.544502  6.221281   \n",
       "154  10.601131  6.426123  5.493845   7.712389   3.569760  7.993786  5.969634   \n",
       "155  10.456393  6.492040  6.147456   7.867307   3.705554  7.129797  5.843678   \n",
       "156   9.736553  6.085462  5.575046  10.184738   2.502134  7.013732  5.174297   \n",
       "157  10.386735  7.403433  6.964953   7.563864   2.896664  8.834118  5.087135   \n",
       "\n",
       "      1320_at  1405_i_at   1431_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0    4.867742  10.289692  3.285293  ...             11.181759   \n",
       "1    5.380585   8.251765  3.226581  ...             11.278896   \n",
       "2    5.072060  10.077566  3.227613  ...             11.186446   \n",
       "3    5.050528   6.401838  3.129943  ...             11.114506   \n",
       "4    5.118793   6.924959  3.555628  ...             11.049942   \n",
       "..        ...        ...       ...  ...                   ...   \n",
       "153  6.446083   7.601814  5.597363  ...             13.002976   \n",
       "154  4.660047   7.245230  3.763940  ...             13.509037   \n",
       "155  5.287788   5.400974  3.867667  ...             12.011763   \n",
       "156  4.270660   6.164104  5.851820  ...             12.588995   \n",
       "157  7.664488   9.760174  3.999645  ...             12.504308   \n",
       "\n",
       "     AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0               10.762042            12.961899            12.688069   \n",
       "1               10.922836            13.101919            12.879850   \n",
       "2               10.775110            12.952916            12.706673   \n",
       "3               10.843346            13.076192            12.767658   \n",
       "4               10.619544            12.897566            12.632525   \n",
       "..                    ...                  ...                  ...   \n",
       "153             12.574812            14.100213            13.910309   \n",
       "154             13.119966            14.622678            14.482744   \n",
       "155             11.424249            13.652698            13.495931   \n",
       "156             11.769854            13.926275            13.862556   \n",
       "157             11.773247            13.916767            13.644173   \n",
       "\n",
       "     AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0          3.725097        3.438851        2.985189         2.687256   \n",
       "1          3.575279        3.394276        2.951872         2.595775   \n",
       "2          3.756748        3.593477        3.179602         2.670777   \n",
       "3          3.747672        3.292814        2.999690         2.707248   \n",
       "4          3.824783        3.472515        2.928189         2.604355   \n",
       "..              ...             ...             ...              ...   \n",
       "153        5.495707        5.550453        4.587382         4.348775   \n",
       "154        8.804711        4.897431        6.028813         2.748260   \n",
       "155        4.033132        3.697196        3.484437         3.505660   \n",
       "156       10.171430        7.839900        9.014192         2.289525   \n",
       "157        3.629679        3.551091        3.064020         2.982234   \n",
       "\n",
       "     AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0           3.182581         3.151897  \n",
       "1           3.004451         3.046263  \n",
       "2           3.067572         3.205570  \n",
       "3           3.185152         3.118335  \n",
       "4           3.118041         3.041668  \n",
       "..               ...              ...  \n",
       "153         4.871972         4.730194  \n",
       "154         3.739844         3.184603  \n",
       "155         3.900688         3.830304  \n",
       "156         2.987165         2.875362  \n",
       "157         3.360652         3.114210  \n",
       "\n",
       "[158 rows x 54675 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "153    0\n",
       "154    0\n",
       "155    0\n",
       "156    0\n",
       "157    0\n",
       "Name: cancer_type, Length: 158, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "# Input df, return X,y for training\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    # Drop type Columns\n",
    "    if \"type\" in df.columns:\n",
    "        df = df.drop(columns=\"type\")\n",
    "\n",
    "    # Convert 'cancer_type' column to binary type: normal = 0, other = 1\n",
    "    if 'cancer_type' in df.columns and not df['cancer_type'].isin([0, 1]).all():\n",
    "        df['cancer_type'] = df['cancer_type'].map({'normal': 0}).fillna(1).astype(int)\n",
    "    \n",
    "    # Get X,y\n",
    "    target = 'cancer_type'\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "# Display proccesed data\n",
    "X_r,y_r = preprocessing(df_renal_cancer)\n",
    "\n",
    "display(X_r,y_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d99bf",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b80933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "def feature_selection(X, y, k_anova=500, k_mutual=500, combine_features=True):\n",
    "    \n",
    "    # Perform ANOVA feature selection\n",
    "    anova_selector = SelectKBest(score_func=f_classif, k=k_anova)\n",
    "    anova_selector.fit(X, y)\n",
    "    X_anova = set(X.columns[anova_selector.get_support()])\n",
    "\n",
    "    # Perform Mutual Information feature selection\n",
    "    mutual_info_selector = SelectKBest(score_func=mutual_info_classif, k=k_mutual)\n",
    "    mutual_info_selector.fit(X, y)\n",
    "    X_mut = set(X.columns[mutual_info_selector.get_support()])\n",
    "\n",
    "    selected_features = X_anova.union(X_mut)\n",
    "\n",
    "    # Subset data with selected features\n",
    "    X_reduce = X[list(selected_features)]\n",
    "    return X_reduce\n",
    "\n",
    "X_r = feature_selection(X_r, y_r, k_anova=100, k_mutual=100, combine_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdae16-415c-422b-aa36-e1e4c43e0998",
   "metadata": {},
   "source": [
    "## Training the Models and Returning their LOOCV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4241ee43-42a6-431e-ad77-da8b80857d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "# Function Definition\n",
    "def perform_model(X, y, max_iter=1000):\n",
    "    model = LogisticRegression(penalty='l1', solver='saga', max_iter=max_iter, random_state=42)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracy_scores, recall_scores, f1_scores = [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # Train the final model on the entire dataset\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Print cross-validation results\n",
    "    print(\"\\nCross-Validation Results:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracy_scores):.2f} ± {np.std(accuracy_scores):.2f}\")\n",
    "    print(f\"Mean Recall: {np.mean(recall_scores):.2f} ± {np.std(recall_scores):.2f}\")\n",
    "    print(f\"Mean F1 Score: {np.mean(f1_scores):.2f} ± {np.std(f1_scores):.2f}\")\n",
    "\n",
    "# Return the model and summary results\n",
    "    return {\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7505298-1810-46d2-8b4e-96c3f0eed2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results:\n",
      "Mean Accuracy: 0.92 ± 0.06\n",
      "Mean Recall: 0.90 ± 0.09\n",
      "Mean F1 Score: 0.92 ± 0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(max_iter=5000, penalty='l1', random_state=42, solver='saga')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = perform_model(X_r, y_r, max_iter=5000)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c2d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6a9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/ledamduyen/Desktop/CS 539/project/dataset/clean/test_data.csv')\n",
    "df_renal_test = df_test[df_test['cancer_type'].isin(['normal', 'renal'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3e8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = preprocessing(df_renal_test)\n",
    "X_test = X_test[X_r.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef89cd4-0aa2-486a-a4dc-ccb673e2ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation on Test Dataset:\n",
      "Accuracy: 0.97\n",
      "Recall: 1.00\n",
      "F1 Score: 0.86\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        52\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.97        58\n",
      "   macro avg       0.88      0.98      0.92        58\n",
      "weighted avg       0.97      0.97      0.97        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the final trained model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Model Evaluation on Test Dataset:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dafa6e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['renal.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, 'renal.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
